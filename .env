# Local LLM Configuration
USE_LOCAL_LLM=true
LOCAL_LLM_API_URL=http://localhost:11434
LOCAL_LLM_API_TYPE=ollama
LOCAL_LLM_MODEL=llama3.2:1b

# Max iterations for improvement loop
MAX_IMPROVEMENT_ITERATIONS=3

# OpenAI Configuration (used as fallback if local LLM is disabled)
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_MODEL_CODER=gpt-4
# OPENAI_MODEL_REVIEWER=gpt-4

# Azure DevOps Configuration
# AZURE_DEVOPS_ORG=your_organization
# AZURE_DEVOPS_PROJECT=your_project
# AZURE_DEVOPS_PAT=your_personal_access_token
